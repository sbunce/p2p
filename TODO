TODO

-The new logic to delete orphan hashes will delete hashes for downloading files.
When download running have server_index::scan_share check with client_server_bridge
to see if hash belongs to running download. When download finishes add an entry
to share that points at the file in the download directory. Scan share should
remove the hash and database entry when the file is moved.

-Make a class called client_server_bridge that's a singleton which keeps track of
what files are downloading and what blocks are available. Also, the
upload/download speed calculators can be contained within this class. This will
solve problem when serving partially downloaded files. There might be blocks that
exist on the HDD that are not actually recieved (when block beyond EOF is
received and file is padded with NULLs).

-Have a possible response to a P_SEND_BLOCK be a P_WAIT, which should trigger a
8 second wait before attempting another P_SEND_BLOCK request. It should also
trigger something with existing P_SEND_BLOCK requests. Should they be
re_requested immediately from other servers? There is a problem with un-expecting
responses. What about having a new command server->client that tells the client
buffer to un-expect? The server should send P_WAIT when the client is downloading
a hash tree (check for <hash>_download).

-The total upload speed should include requests the client is making. Not just
server upload. Make a singleton for a speed_calculator for up_down speeds.

-Need to make a limit on the client to not request more than 256 concurrent slots.


WINDOWS PORTABILITY

-New line not working in terminal. \r\n?

-Need to figure out CryptGenRandom for encryption::PRNG(). encryption::PRNG()
currently set to kill program on windows.
http://msdn.microsoft.com/en-us/library/aa379942.aspx

-Look in to a makefile project in visual C++. See if that can be made compatible
with gnu-make.


DEFERRED FEATURES

-client::set_download_directory() not doing anything but saving setting. Make it
impossible to change if there are downloads going.

-Hashes need to be removed for files that don't exist in share. Deferred because
it makes testing difficult.

-Support for multiple share directories.


IDEAS

-Don't allow clients to download who have the P2P port blocked. When a server is
connected to it should try to connect back to the client(more precisely the
server running at the address the client connected from). If the server can't
connect back it should deny the clients connection. This will make things
totally not work if there is NAT in the way or the server somehow isn't running.

-Let the user set up bandwidth profiles that can be quickly selected. The user
could create one for games/night time/bla bla. Then have a timer that can select
the profile based on time of day.

-Think about combining hash tree's in to one file. Keep track of starting
locations in DB. Perhaps have a memmove type opteration one a file where hashes
can be moved to get rid of gaps due to removed files. The intermediate step of
the memmove operation would basically be a journal.


GUI IDEAS

-When right clicking a download a option to get detailed info.

-A pulldown box in the preferences that lets you add directories to share.

-Replace IP in the search treeview with a description.

-Replace IP in the download treeview with a seeder/leecher count.


OVERLAY NETWORK IDEAS

-XOR key system where keys are a hash of IP addresses so that nodes are
organized by distance (distance measured in hops). Can keys directly be IP
addresses since they are unique and organized by network?

-Trackers which are organized in to a tree structure such that if the user adds
a tracker the user will also get to see the files of the trackers that tracker
trusts and the files that that tracker trusts etc. Have an option to limit trust
levels to direct trust only, one level inheritance and all level inheritance.
Children should be able to point to their parents.

-What about having one large overlay network reserved for tracker discovery.
Have a rule that says an individual can advertise a tracker once per day (or
some large time period). That'd make traffic on the large overlay very minimal.
